{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key Points: CatBoost**\n",
    "\n",
    "1. **Definition**:  \n",
    "   CatBoost (Categorical Boosting) is a high-performance, open-source gradient boosting library designed to handle categorical features efficiently and provide high accuracy with minimal parameter tuning.\n",
    "\n",
    "2. **Key Features**:  \n",
    "   - **Handles Categorical Data**: Automatically processes categorical features without the need for extensive preprocessing (e.g., one-hot encoding or label encoding).  \n",
    "   - **Supports GPU Acceleration**: Faster training with GPU support for large datasets.  \n",
    "   - **Robust to Overfitting**: Incorporates techniques like ordered boosting to reduce overfitting.  \n",
    "   - **Minimal Parameter Tuning**: Often delivers strong results with default hyperparameters.  \n",
    "   - **Cross-Validation Support**: Built-in tools for cross-validation and parameter tuning.\n",
    "\n",
    "3. **Advantages**:  \n",
    "   - Efficient with datasets containing many categorical features.  \n",
    "   - Outperforms traditional models in many real-world scenarios.  \n",
    "   - Provides insights into **feature importance** for better explainability.  \n",
    "   - Fast implementation and easy to use.  \n",
    "\n",
    "4. **Disadvantages**:  \n",
    "   - Higher memory consumption compared to some simpler models.  \n",
    "   - May not perform as well on extremely small datasets.  \n",
    "   - Requires careful handling when deploying due to its dependency on the CatBoost library.  \n",
    "\n",
    "5. **Applications**:  \n",
    "   - Fraud detection.  \n",
    "   - Recommendation systems.  \n",
    "   - Predictive modeling tasks in finance, healthcare, and retail.  \n",
    "   - Any machine learning task with complex categorical data.  \n",
    "\n",
    "6. **Best Practices**:  \n",
    "   - Use **CatBoostâ€™s native handling of categorical features** instead of manual encoding.  \n",
    "   - Leverage **GPU support** for faster training on large datasets.  \n",
    "   - Perform hyperparameter tuning for optimal performance (e.g., tuning `iterations`, `learning_rate`, `depth`).  \n",
    "   - Use **early stopping** to avoid overfitting.  \n",
    "   - Monitor CatBoost's built-in evaluation metrics during training to assess model performance.\n",
    "\n",
    "7. **Key Hyperparameters**:  \n",
    "   - `iterations`: The number of boosting iterations.  \n",
    "   - `learning_rate`: Step size for each iteration.  \n",
    "   - `depth`: Maximum depth of the tree.  \n",
    "   - `l2_leaf_reg`: L2 regularization term to prevent overfitting.  \n",
    "   - `cat_features`: Specify categorical features for automatic handling.  \n",
    "   - `loss_function`: Loss function to optimize (e.g., `Logloss` for classification, `RMSE` for regression).  \n",
    "\n",
    "8. **Common Metrics for Evaluation**:  \n",
    "   - **Classification**: Accuracy, F1-score, ROC-AUC.  \n",
    "   - **Regression**: RMSE, MAE, R-squared.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**  \n",
    "CatBoost is a powerful and efficient gradient boosting library that excels in handling datasets with categorical features. It is particularly well-suited for real-world applications requiring high accuracy and minimal preprocessing, making it a valuable tool for data scientists and machine learning practitioners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset of titanic\n",
    "df = sns.load_dataset('titanic')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived       0\n",
       "pclass         0\n",
       "sex            0\n",
       "age            0\n",
       "sibsp          0\n",
       "parch          0\n",
       "fare           0\n",
       "embarked       0\n",
       "class          0\n",
       "who            0\n",
       "adult_male     0\n",
       "embark_town    0\n",
       "alive          0\n",
       "alone          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute missing values using knn imputers in fare and age\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df[['fare' , 'age' ]] = imputer.fit_transform(df[['fare' , 'age']])\n",
    "\n",
    "# impute missing values using mode in embarked and embark_town using simple imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[['embarked' , 'embark_town']] = imputer.fit_transform(df[['embarked' , 'embark_town']])\n",
    "\n",
    "# drop deck column\n",
    "df = df.drop(['deck' ] , axis=1)\n",
    "\n",
    "# df missing values\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    category\n",
      " 3   age          891 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     891 non-null    category\n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    category\n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  embark_town  891 non-null    category\n",
      " 12  alive        891 non-null    category\n",
      " 13  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(6), float64(2), int64(4)\n",
      "memory usage: 49.6 KB\n"
     ]
    }
   ],
   "source": [
    "# convert each category column to category\n",
    "categorical_columns = df.select_dtypes(include=['object' , 'category']).columns\n",
    "\n",
    "# add this as a new column in the dataframe\n",
    "df[categorical_columns] = df[categorical_columns].astype('category')\n",
    "\n",
    "# lets check\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "X = df.drop(['survived' ] , axis=1)\n",
    "y = df['survived']\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size=0.2 , random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 1.0\n",
      "[[105   0]\n",
      " [  0  74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       105\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       179\n",
      "   macro avg       1.00      1.00      1.00       179\n",
      "weighted avg       1.00      1.00      1.00       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = CatBoostClassifier(iterations=100\n",
    "                           , learning_rate=0.1\n",
    "                           , depth=3\n",
    "                           , loss_function='Logloss'\n",
    "                           , eval_metric='Accuracy'\n",
    "                           , verbose=False)\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train , y_train , cat_features=categorical_columns.tolist())\n",
    "\n",
    "# predict the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "accuracy = accuracy_score(y_test , y_pred)\n",
    "print(f'Accuracy of the model is {accuracy}')\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test , y_pred)\n",
    "print(cm)\n",
    "\n",
    "# classification report\n",
    "cr = classification_report(y_test , y_pred)\n",
    "print(cr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.7227460425659444\n",
      "R-squared: 0.42178991118535847\n",
      "Mean Absolute Error: 0.703186662750036\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Load the tips dataset using seaborn\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "# Create a dictionary to store LabelEncoders for each categorical column\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode categorical features and store encoders\n",
    "categorical_cols = ['sex', 'smoker', 'day', 'time']\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    tips[col] = le.fit_transform(tips[col])  # Encode the column\n",
    "    label_encoders[col] = le  # Store the encoder\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = tips[['total_bill', 'sex', 'smoker', 'day', 'time', 'size']]\n",
    "y = tips['tip']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the CatBoostRegressor model\n",
    "model = CatBoostRegressor(iterations=100, learning_rate=0.1, depth=4, random_state=42, verbose=0 )\n",
    "model.fit(X_train, y_train, cat_features=[1, 2, 3, 4])  # Specify categorical feature indices\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Inverse transform the encoded features in the original DataFrame\n",
    "for col in categorical_cols:\n",
    "    tips[col] = label_encoders[col].inverse_transform(tips[col].astype(int))  # Inverse transform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
