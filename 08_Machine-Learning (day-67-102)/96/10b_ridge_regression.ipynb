{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "Ridge Regression is a type of linear regression that includes a regularization term to prevent overfitting. The regularization term is the L2 penalty, which is the sum of the squared coefficients multiplied by a regularization parameter (lambda). This penalty term shrinks the coefficients towards zero, but not exactly zero, which helps to reduce the model complexity and multicollinearity.\n",
    "\n",
    "The objective function for Ridge Regression is:\n",
    "\n",
    "$$\n",
    "\\text{Minimize} \\left( \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2 \\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ y_i $ is the actual value\n",
    "- $ \\hat{y}_i $ is the predicted value\n",
    "- $ \\beta_j $ are the coefficients\n",
    "- $ \\lambda $ is the regularization parameter\n",
    "\n",
    "Ridge Regression is particularly useful when there are many predictors, and multicollinearity is present. It helps to improve the model's generalization by adding bias but reducing variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.8 1.4]\n",
      "Intercept: 4.5\n"
     ]
    }
   ],
   "source": [
    "# import libraries \n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "# Target variable\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "\n",
    "# Create a Ridge regression model\n",
    "ridge_model = Ridge(alpha=1.0) # aplha is the equivalent of lambda in the equation\n",
    "# Fit the model to the data\n",
    "ridge_model.fit(X, y)\n",
    "\n",
    "# Coefficients\n",
    "print(\"Coefficients:\", ridge_model.coef_)\n",
    "# Intercept\n",
    "print(\"Intercept:\", ridge_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Simple Linear Regression and Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries & Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge , LinearRegression\n",
    "from sklearn.model_selection import train_test_split    \n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a subset of columns for simplicity\n",
    "columns_to_use = ['survived', 'pclass' , 'sex' , 'age', 'fare']\n",
    "df = df[columns_to_use]\n",
    "# Handling missing values\n",
    "df['age'] = df['age'].fillna(df['age'].median())\n",
    "df['fare'] = df['fare'].fillna(df['fare'].median())\n",
    "\n",
    "# Defining features and target variable\n",
    "X = df.drop('survived', axis=1)\n",
    "y = df['survived']\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline for preprocessing and modeling\n",
    "categorical_features = ['sex']\n",
    "numeric_features = ['pclass', 'age', 'fare']\n",
    "\n",
    "# preprocess\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "# Create a linear regression pipeline\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "# Create a Ridge regression pipeline\n",
    "ridge_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', Ridge(alpha=1.0))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.1371682053082538\n",
      "Ridge Regression MSE: 0.13718838549258475\n",
      "Linear Regression R-squared: 0.4343621021516396\n",
      "Ridge Regression R-squared: 0.4342788855124957\n",
      "Linear Regression MAE: 0.287745694224429\n",
      "Ridge Regression MAE: 0.28820775939135757\n",
      "Linear Regression MAPE: 645238867583785.1\n",
      "Ridge Regression MAPE: 645983981155847.0\n"
     ]
    }
   ],
   "source": [
    "# Train the linear regression model\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "# Train the Ridge regression model\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred_lr = lr_pipeline.predict(X_test)\n",
    "y_pred_ridge = ridge_pipeline.predict(X_test)\n",
    "# Calculate mean squared error\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "# Calculate R-squared\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "# Calculate mean absolute error\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "# Calculate mean absolute percentage error\n",
    "mape_lr = mean_absolute_percentage_error(y_test, y_pred_lr)\n",
    "mape_ridge = mean_absolute_percentage_error(y_test, y_pred_ridge)\n",
    "# Print the results\n",
    "print(\"Linear Regression MSE:\", mse_lr)\n",
    "print(\"Ridge Regression MSE:\", mse_ridge)\n",
    "print(\"Linear Regression R-squared:\", r2_lr)\n",
    "print(\"Ridge Regression R-squared:\", r2_ridge)\n",
    "print(\"Linear Regression MAE:\", mae_lr)\n",
    "print(\"Ridge Regression MAE:\", mae_ridge)\n",
    "print(\"Linear Regression MAPE:\", mape_lr)\n",
    "print(\"Ridge Regression MAPE:\", mape_ridge)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
