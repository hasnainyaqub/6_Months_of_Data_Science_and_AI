{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings # to ignore warnings\n",
    "warnings.filterwarnings('ignore')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tips dataset\n",
    "df = sns.load_dataset('tips')\n",
    "\n",
    "# preprocessing \n",
    "# encode categorical columns using loop\n",
    "le_list = {}\n",
    "for col in df.select_dtypes(include=['object' , 'category']):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df[col])\n",
    "    df[col] = le.transform(df[col])\n",
    "    le_list[col] = le\n",
    "\n",
    "# Selectig the features and label\n",
    "X = df.drop('tip', axis=1)\n",
    "y = df['tip']\n",
    "# splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "# Buil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 2s 92ms/step - loss: 3.1960 - val_loss: 2.6112\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 3.0172 - val_loss: 2.4310\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.8380 - val_loss: 2.2525\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.6595 - val_loss: 2.0722\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.4761 - val_loss: 1.8899\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.2827 - val_loss: 1.7008\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.0779 - val_loss: 1.5083\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.8695 - val_loss: 1.3418\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.6660 - val_loss: 1.2208\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.4618 - val_loss: 1.1041\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.2814 - val_loss: 1.0342\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.1547 - val_loss: 1.0236\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.0777 - val_loss: 1.0318\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.0233 - val_loss: 1.0244\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9922 - val_loss: 1.0061\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9667 - val_loss: 0.9767\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.9429 - val_loss: 0.9615\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.9238 - val_loss: 0.9544\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.9090 - val_loss: 0.9351\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.8928 - val_loss: 0.9146\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8798 - val_loss: 0.9025\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8664 - val_loss: 0.8917\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8573 - val_loss: 0.8751\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.8451 - val_loss: 0.8702\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.8374 - val_loss: 0.8636\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8264 - val_loss: 0.8731\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8169 - val_loss: 0.8785\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8114 - val_loss: 0.8606\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8057 - val_loss: 0.8461\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8013 - val_loss: 0.8383\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7980 - val_loss: 0.8528\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7904 - val_loss: 0.8427\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7856 - val_loss: 0.8380\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7842 - val_loss: 0.8340\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7791 - val_loss: 0.8403\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.7762 - val_loss: 0.8451\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7697 - val_loss: 0.8267\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7665 - val_loss: 0.8254\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.7627 - val_loss: 0.8267\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.7607 - val_loss: 0.8221\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.7539 - val_loss: 0.8118\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.7487 - val_loss: 0.8025\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.7473 - val_loss: 0.8118\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.7427 - val_loss: 0.8277\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7393 - val_loss: 0.8296\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.7372 - val_loss: 0.8259\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.7324 - val_loss: 0.8077\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.7318 - val_loss: 0.8183\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.7285 - val_loss: 0.8211\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.7227 - val_loss: 0.8249\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.7213 - val_loss: 0.8088\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.7184 - val_loss: 0.8046\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8025\n",
      "Test loss: 0.80247962474823\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# building the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "\n",
    "# early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# training the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
    "\n",
    "# evaluating the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
